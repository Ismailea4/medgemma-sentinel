{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install huggingface_hub llama-cpp-python"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "INkZxAG6cEJW",
        "outputId": "1876198b-993e-474b-d72a-ea43bfef6aa8"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: huggingface_hub in /usr/local/lib/python3.12/dist-packages (1.4.1)\n",
            "Collecting llama-cpp-python\n",
            "  Downloading llama_cpp_python-0.3.16.tar.gz (50.7 MB)\n",
            "\u001b[2K     \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m50.7/50.7 MB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "  Installing backend dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (3.24.2)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (2025.3.0)\n",
            "Requirement already satisfied: hf-xet<2.0.0,>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.2.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.28.1)\n",
            "Requirement already satisfied: packaging>=20.9 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (26.0)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (6.0.3)\n",
            "Requirement already satisfied: shellingham in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (1.5.4)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.67.3)\n",
            "Requirement already satisfied: typer-slim in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (0.24.0)\n",
            "Requirement already satisfied: typing-extensions>=4.1.0 in /usr/local/lib/python3.12/dist-packages (from huggingface_hub) (4.15.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (2.0.2)\n",
            "Collecting diskcache>=5.6.1 (from llama-cpp-python)\n",
            "  Downloading diskcache-5.6.3-py3-none-any.whl.metadata (20 kB)\n",
            "Requirement already satisfied: jinja2>=2.11.3 in /usr/local/lib/python3.12/dist-packages (from llama-cpp-python) (3.1.6)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (4.12.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (2026.1.4)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx<1,>=0.23.0->huggingface_hub) (3.11)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->huggingface_hub) (0.16.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.12/dist-packages (from jinja2>=2.11.3->llama-cpp-python) (3.0.3)\n",
            "Requirement already satisfied: typer>=0.24.0 in /usr/local/lib/python3.12/dist-packages (from typer-slim->huggingface_hub) (0.24.0)\n",
            "Requirement already satisfied: click>=8.2.1 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (8.3.1)\n",
            "Requirement already satisfied: rich>=12.3.0 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (13.9.4)\n",
            "Requirement already satisfied: annotated-doc>=0.0.2 in /usr/local/lib/python3.12/dist-packages (from typer>=0.24.0->typer-slim->huggingface_hub) (0.0.4)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (4.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.12/dist-packages (from rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (2.19.2)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.12/dist-packages (from markdown-it-py>=2.2.0->rich>=12.3.0->typer>=0.24.0->typer-slim->huggingface_hub) (0.1.2)\n",
            "Downloading diskcache-5.6.3-py3-none-any.whl (45 kB)\n",
            "\u001b[2K   \u001b[90m‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ‚îÅ\u001b[0m \u001b[32m45.5/45.5 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: llama-cpp-python\n",
            "  Building wheel for llama-cpp-python (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for llama-cpp-python: filename=llama_cpp_python-0.3.16-cp312-cp312-linux_x86_64.whl size=4422320 sha256=7ac700d97f8607a88543726b479ba93a497a2a0ad8bb6cda90ea00df5160537f\n",
            "  Stored in directory: /root/.cache/pip/wheels/90/82/ab/8784ee3fb99ddb07fd36a679ddbe63122cc07718f6c1eb3be8\n",
            "Successfully built llama-cpp-python\n",
            "Installing collected packages: diskcache, llama-cpp-python\n",
            "Successfully installed diskcache-5.6.3 llama-cpp-python-0.3.16\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kU-vVFfuUTxe",
        "outputId": "a9a72b5c-13ed-4fcc-fb43-53c7f3f7bb12"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "üì• Fetching Night Sentinel from Hugging Face...\n",
            "üß† Booting Clinical Brain...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "llama_context: n_ctx_per_seq (2048) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
            "llama_kv_cache_unified_iswa: using full-size SWA cache (ref: https://github.com/ggml-org/llama.cpp/pull/13194#issuecomment-2868343055)\n"
          ]
        }
      ],
      "source": [
        "from huggingface_hub import hf_hub_download\n",
        "from llama_cpp import Llama\n",
        "\n",
        "# Make sure your team runs `huggingface-cli login` in their terminal first!\n",
        "\n",
        "# 1. Automatically fetch the model from your Private Hugging Face Repo\n",
        "# (It downloads once and caches it locally on their machine)\n",
        "print(\"üì• Fetching Night Sentinel from Hugging Face...\")\n",
        "model_path = hf_hub_download(\n",
        "    repo_id=\"Ismailea04/medgemma-night-sentinel\", # Replace with your repo\n",
        "    filename=\"medgemma-night-sentinel-Q4_K_M.gguf\"\n",
        ")\n",
        "\n",
        "# 2. Load the GGUF model into local RAM/CPU\n",
        "print(\"üß† Booting Clinical Brain...\")\n",
        "llm = Llama(\n",
        "    model_path=model_path,\n",
        "    n_ctx=2048,       # Memory window for the prompt\n",
        "    verbose=False     # Set to True if you want to see C++ debug logs\n",
        ")\n",
        "\n",
        "# 3. The Function Saad can use for his Agent\n",
        "def trigger_night_sentinel(patient_profile, vital_signs_anomaly):\n",
        "    \"\"\"\n",
        "    Feeds an anomaly to the steered MedGemma model.\n",
        "    \"\"\"\n",
        "    # Using the strict MedGemma Instruction-Tuning Template\n",
        "    prompt = (\n",
        "        f\"<start_of_turn>user\\n\"\n",
        "        f\"[NIGHT SENTINEL SYSTEM]\\n\"\n",
        "        f\"Patient Profile: {patient_profile}\\n\"\n",
        "        f\"Event/Anomaly: {vital_signs_anomaly}\\n\"\n",
        "        f\"    TASK:\\n\"\n",
        "        f\"1. Compare the current data to the patient's specific baseline (Name it : ##Comparaison).\\n\"\n",
        "        f\"2. Identify any clinical anomalies (Name it : ##Detection).\\n\"\n",
        "        f\"3. Provide a short clinical interpretation of what might be happening (Name it : ##Interpretation).<end_of_turn>\\n\"\n",
        "        f\"<start_of_turn>model\\n\"\n",
        "    )\n",
        "\n",
        "    response = llm(\n",
        "        prompt,\n",
        "        max_tokens=400,\n",
        "        stop=[\"<end_of_turn>\"], # Stop generating when the thought is finished\n",
        "        echo=False\n",
        "    )\n",
        "\n",
        "    return response['choices'][0]['text'].strip()\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# --- TEST EXECUTION ---\n",
        "if __name__ == \"__main__\":\n",
        "    profile = \"65yo male, post-operative recovery. Baseline HR 70.\"\n",
        "    anomaly = \"Sudden HR spike to 135 bpm with irregular rhythm, SpO2 92%.\"\n",
        "\n",
        "    print(\"\\nüö® Triggering Alert Analysis...\")\n",
        "    diagnosis = trigger_night_sentinel(profile, anomaly)\n",
        "    print(f\"\\n[SENTINEL REPORT]\\n{diagnosis}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A9rGl7LAcBd0",
        "outputId": "33bdd901-2091-4230-ebaa-77cd8579cf11"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "üö® Triggering Alert Analysis...\n",
            "\n",
            "[SENTINEL REPORT]\n",
            "Here's an analysis of the provided data, broken down into the requested sections:\n",
            "\n",
            "##Comparison\n",
            "\n",
            "*   **Baseline HR:** 70 bpm\n",
            "*   **Current HR:** 135 bpm\n",
            "*   **Current Rhythm:** Irregular\n",
            "*   **SpO2:** 92%\n",
            "\n",
            "##Detection\n",
            "\n",
            "*   **Significant HR Spike:** The patient's heart rate has increased from 70 bpm to 135 bpm.\n",
            "*   **Irregular Rhythm:** The heart rate is no longer regular.\n",
            "*   **Hypoxia:** The patient's oxygen saturation is 92%, which is below the typical normal range of 95-100% and indicates a degree of hypoxemia.\n",
            "\n",
            "##Interpretation\n",
            "\n",
            "The patient is experiencing a sudden and significant increase in heart rate with an irregular rhythm, accompanied by a drop in oxygen saturation. This suggests a possible cardiac event (e.g., arrhythmia, possibly atrial fibrillation or other irregular rhythm), and/or a respiratory issue. The irregular rhythm could be concerning, and the hypoxia needs to be investigated. Given the post-operative status, other possibilities include:\n",
            "*   **Pain or Anxiety:** Post-operative pain and anxiety can elevate heart rate.\n",
            "*   **Medication Effects:** Some medications can cause tachycardia or affect oxygen saturation.\n",
            "*   **Underlying Cardiac Condition:** The spike could be a sign of an existing but previously undetected heart problem.\n",
            "*   **Pulmonary Issue:** A pulmonary embolism or other respiratory distress could lead to hypoxia and potentially affect the heart rate.\n",
            "\n",
            "This situation requires immediate attention. The patient should be reassessed to determine the underlying cause, and appropriate interventions (e.g., medication, oxygen, further cardiac monitoring) should be implemented.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ubZYiB0IeUPJ"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}