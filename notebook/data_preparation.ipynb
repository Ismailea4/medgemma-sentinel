{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ebd0d554",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Directories created\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "from pathlib import Path\n",
    "\n",
    "# Set paths\n",
    "RAW_DATA_DIR = Path('../data/raw')\n",
    "ADOLESCENT_DIR = RAW_DATA_DIR / 'hr_adolescent'\n",
    "MIMIC_DIR = RAW_DATA_DIR / 'hr_mimic_iii'\n",
    "\n",
    "# Create output directories\n",
    "PROCESSED_DIR = Path('../data/processed')\n",
    "ADOLESCENT_OUTPUT_DIR = PROCESSED_DIR / 'hr_adolescent'\n",
    "MIMIC_OUTPUT_DIR = PROCESSED_DIR / 'hr_mimic_iii'\n",
    "\n",
    "ADOLESCENT_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "MIMIC_OUTPUT_DIR.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"✓ Directories created\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1f5976e",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "\n",
    "This notebook prepares the heart rate dataset from two sources:\n",
    "1. **hr_adolescent**: Fitbit heart rate data from adolescent subjects\n",
    "2. **hr_mimic_iii**: MIMIC-III clinical heart rate data\n",
    "\n",
    "## Tasks:\n",
    "- Split adolescent heart rate data by subject\n",
    "- Create subject metadata JSON file\n",
    "- Clean MIMIC-III data (remove empty rows and high-NaN columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a7e8760",
   "metadata": {},
   "source": [
    "## Part 1: Process Adolescent Heart Rate Data\n",
    "\n",
    "### 1.1 Load and Split Heart Rate Data by Subject"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "335f6c96",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading heart rate data from ..\\data\\raw\\hr_adolescent\\Fitbit-heart-rate.txt...\n",
      "✓ Loaded 2,771,807 records\n",
      "  Columns: ['Subject code number', 'Local datetime [ISO8601]', 'Local date [yyyy-mm-dd]', 'Local time [hh:mm]', 'UTC offset [hr]', 'heart rate [#/min]']\n",
      "  Unique subjects: 24\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject code number</th>\n",
       "      <th>Local datetime [ISO8601]</th>\n",
       "      <th>Local date [yyyy-mm-dd]</th>\n",
       "      <th>Local time [hh:mm]</th>\n",
       "      <th>UTC offset [hr]</th>\n",
       "      <th>heart rate [#/min]</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903</td>\n",
       "      <td>2019-10-15T00:00:00+0200</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>903</td>\n",
       "      <td>2019-10-15T00:01:00+0200</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>00:01</td>\n",
       "      <td>2</td>\n",
       "      <td>67</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>903</td>\n",
       "      <td>2019-10-15T00:02:00+0200</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>00:02</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>903</td>\n",
       "      <td>2019-10-15T00:03:00+0200</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>00:03</td>\n",
       "      <td>2</td>\n",
       "      <td>68</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>903</td>\n",
       "      <td>2019-10-15T00:04:00+0200</td>\n",
       "      <td>2019-10-15</td>\n",
       "      <td>00:04</td>\n",
       "      <td>2</td>\n",
       "      <td>66</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject code number  Local datetime [ISO8601] Local date [yyyy-mm-dd]  \\\n",
       "0                  903  2019-10-15T00:00:00+0200              2019-10-15   \n",
       "1                  903  2019-10-15T00:01:00+0200              2019-10-15   \n",
       "2                  903  2019-10-15T00:02:00+0200              2019-10-15   \n",
       "3                  903  2019-10-15T00:03:00+0200              2019-10-15   \n",
       "4                  903  2019-10-15T00:04:00+0200              2019-10-15   \n",
       "\n",
       "  Local time [hh:mm]  UTC offset [hr]  heart rate [#/min]  \n",
       "0              00:00                2                  64  \n",
       "1              00:01                2                  67  \n",
       "2              00:02                2                  66  \n",
       "3              00:03                2                  68  \n",
       "4              00:04                2                  66  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the heart rate data (large file - may take a moment)\n",
    "hr_file = ADOLESCENT_DIR / 'Fitbit-heart-rate.txt'\n",
    "print(f\"Loading heart rate data from {hr_file}...\")\n",
    "\n",
    "# Read the large file\n",
    "hr_data = pd.read_csv(hr_file)\n",
    "print(f\"✓ Loaded {len(hr_data):,} records\")\n",
    "print(f\"  Columns: {list(hr_data.columns)}\")\n",
    "print(f\"  Unique subjects: {hr_data['Subject code number'].nunique()}\")\n",
    "\n",
    "# Display sample data\n",
    "hr_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b4ada0bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Splitting data for 24 subjects...\n",
      "  ✓ Subject 903: 118,354 records → subject_903_hr.csv\n",
      "  ✓ Subject 907: 108,150 records → subject_907_hr.csv\n",
      "  ✓ Subject 911: 122,065 records → subject_911_hr.csv\n",
      "  ✓ Subject 912: 118,311 records → subject_912_hr.csv\n",
      "  ✓ Subject 914: 109,735 records → subject_914_hr.csv\n",
      "  ✓ Subject 918: 119,580 records → subject_918_hr.csv\n",
      "  ✓ Subject 919: 111,615 records → subject_919_hr.csv\n",
      "  ✓ Subject 926: 123,220 records → subject_926_hr.csv\n",
      "  ✓ Subject 929: 121,288 records → subject_929_hr.csv\n",
      "  ✓ Subject 936: 113,827 records → subject_936_hr.csv\n",
      "  ✓ Subject 941: 122,008 records → subject_941_hr.csv\n",
      "  ✓ Subject 943: 116,360 records → subject_943_hr.csv\n",
      "  ✓ Subject 944: 113,665 records → subject_944_hr.csv\n",
      "  ✓ Subject 959: 116,882 records → subject_959_hr.csv\n",
      "  ✓ Subject 962: 123,846 records → subject_962_hr.csv\n",
      "  ✓ Subject 964: 102,367 records → subject_964_hr.csv\n",
      "  ✓ Subject 967: 114,783 records → subject_967_hr.csv\n",
      "  ✓ Subject 973: 124,691 records → subject_973_hr.csv\n",
      "  ✓ Subject 974: 113,884 records → subject_974_hr.csv\n",
      "  ✓ Subject 976: 109,064 records → subject_976_hr.csv\n",
      "  ✓ Subject 981: 112,110 records → subject_981_hr.csv\n",
      "  ✓ Subject 987: 112,867 records → subject_987_hr.csv\n",
      "  ✓ Subject 990: 111,656 records → subject_990_hr.csv\n",
      "  ✓ Subject 995: 111,479 records → subject_995_hr.csv\n",
      "\n",
      "✓ All heart rate files saved to ..\\data\\processed\\hr_adolescent\n"
     ]
    }
   ],
   "source": [
    "# Split heart rate data by subject and save to individual CSV files\n",
    "subject_codes = hr_data['Subject code number'].unique()\n",
    "print(f\"Splitting data for {len(subject_codes)} subjects...\")\n",
    "\n",
    "for subject_code in subject_codes:\n",
    "    # Filter data for this subject\n",
    "    subject_hr = hr_data[hr_data['Subject code number'] == subject_code]\n",
    "    \n",
    "    # Save to CSV\n",
    "    output_file = ADOLESCENT_OUTPUT_DIR / f'subject_{subject_code}_hr.csv'\n",
    "    subject_hr.to_csv(output_file, index=False)\n",
    "    \n",
    "    print(f\"  ✓ Subject {subject_code}: {len(subject_hr):,} records → {output_file.name}\")\n",
    "\n",
    "print(f\"\\n✓ All heart rate files saved to {ADOLESCENT_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8dbd4c",
   "metadata": {},
   "source": [
    "### 1.2 Create Subject Information JSON File"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d7041fdd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Loaded population data: 24 subjects\n",
      "  Columns: ['Subject code number', 'Gender [M=male F=female]', 'Length [cm]', 'Weight [kg]', 'Age [yr]', 'HbA1C_1 [yyyy]', 'HbA1C_1 [mm]', 'HbA1C_1 [mmol/mol]', 'HbA1C_2 [yyyy]', 'HbA1C_2 [mm]', 'HbA1C_2 [mmol/mol]', 'Pump brand', 'Pump model', 'FGM/CGM brand', 'FGM/CGM model', 'Activity tracker brand', 'Activity tracker model']\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Subject code number</th>\n",
       "      <th>Gender [M=male F=female]</th>\n",
       "      <th>Length [cm]</th>\n",
       "      <th>Weight [kg]</th>\n",
       "      <th>Age [yr]</th>\n",
       "      <th>HbA1C_1 [yyyy]</th>\n",
       "      <th>HbA1C_1 [mm]</th>\n",
       "      <th>HbA1C_1 [mmol/mol]</th>\n",
       "      <th>HbA1C_2 [yyyy]</th>\n",
       "      <th>HbA1C_2 [mm]</th>\n",
       "      <th>HbA1C_2 [mmol/mol]</th>\n",
       "      <th>Pump brand</th>\n",
       "      <th>Pump model</th>\n",
       "      <th>FGM/CGM brand</th>\n",
       "      <th>FGM/CGM model</th>\n",
       "      <th>Activity tracker brand</th>\n",
       "      <th>Activity tracker model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>903</td>\n",
       "      <td>F</td>\n",
       "      <td>154.5</td>\n",
       "      <td>42.7</td>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>7</td>\n",
       "      <td>37</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>Medtronic</td>\n",
       "      <td>MiniMed 640G</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Freestyle Libre</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>Inspire HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>907</td>\n",
       "      <td>F</td>\n",
       "      <td>168.2</td>\n",
       "      <td>58.7</td>\n",
       "      <td>11</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>54</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Medtronic</td>\n",
       "      <td>MiniMed 640G</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Freestyle Libre</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>Inspire HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>911</td>\n",
       "      <td>F</td>\n",
       "      <td>172.0</td>\n",
       "      <td>59.8</td>\n",
       "      <td>15</td>\n",
       "      <td>2019</td>\n",
       "      <td>10</td>\n",
       "      <td>56</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>Omnipod</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Freestyle Libre</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>Inspire HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>912</td>\n",
       "      <td>M</td>\n",
       "      <td>162.0</td>\n",
       "      <td>74.4</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>6</td>\n",
       "      <td>53</td>\n",
       "      <td>2020.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>Medtronic</td>\n",
       "      <td>MiniMed 640G and MiniMed 670G</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Freestyle Libre</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>Inspire HR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>914</td>\n",
       "      <td>M</td>\n",
       "      <td>186.6</td>\n",
       "      <td>68.5</td>\n",
       "      <td>13</td>\n",
       "      <td>2019</td>\n",
       "      <td>9</td>\n",
       "      <td>35</td>\n",
       "      <td>2019.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>Medtronic</td>\n",
       "      <td>MiniMed 640G</td>\n",
       "      <td>Abbott</td>\n",
       "      <td>Freestyle Libre</td>\n",
       "      <td>Fitbit</td>\n",
       "      <td>Inspire HR</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Subject code number Gender [M=male F=female]  Length [cm]  Weight [kg]  \\\n",
       "0                  903                        F        154.5         42.7   \n",
       "1                  907                        F        168.2         58.7   \n",
       "2                  911                        F        172.0         59.8   \n",
       "3                  912                        M        162.0         74.4   \n",
       "4                  914                        M        186.6         68.5   \n",
       "\n",
       "   Age [yr]  HbA1C_1 [yyyy]  HbA1C_1 [mm]  HbA1C_1 [mmol/mol]  HbA1C_2 [yyyy]  \\\n",
       "0        10            2019             7                  37          2019.0   \n",
       "1        11            2019            10                  54          2020.0   \n",
       "2        15            2019            10                  56          2020.0   \n",
       "3        13            2019             6                  53          2020.0   \n",
       "4        13            2019             9                  35          2019.0   \n",
       "\n",
       "   HbA1C_2 [mm]  HbA1C_2 [mmol/mol] Pump brand                     Pump model  \\\n",
       "0          11.0                42.0  Medtronic                   MiniMed 640G   \n",
       "1           1.0                 NaN  Medtronic                   MiniMed 640G   \n",
       "2           1.0                64.0    Omnipod                            NaN   \n",
       "3          12.0                54.0  Medtronic  MiniMed 640G and MiniMed 670G   \n",
       "4          11.0                38.0  Medtronic                   MiniMed 640G   \n",
       "\n",
       "  FGM/CGM brand    FGM/CGM model Activity tracker brand Activity tracker model  \n",
       "0        Abbott  Freestyle Libre                 Fitbit             Inspire HR  \n",
       "1        Abbott  Freestyle Libre                 Fitbit             Inspire HR  \n",
       "2        Abbott  Freestyle Libre                 Fitbit             Inspire HR  \n",
       "3        Abbott  Freestyle Libre                 Fitbit             Inspire HR  \n",
       "4        Abbott  Freestyle Libre                 Fitbit             Inspire HR  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load population/subject information\n",
    "population_file = ADOLESCENT_DIR / 'population.csv'\n",
    "population_data = pd.read_csv(population_file)\n",
    "\n",
    "print(f\"✓ Loaded population data: {len(population_data)} subjects\")\n",
    "print(f\"  Columns: {list(population_data.columns)}\")\n",
    "\n",
    "# Display sample\n",
    "population_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6097c0e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Subject information saved to ..\\data\\processed\\hr_adolescent\\subjects_info.json\n",
      "  Total subjects: 24\n",
      "\n",
      "Sample entry:\n",
      "{\n",
      "  \"subject_code\": 903,\n",
      "  \"gender\": \"F\",\n",
      "  \"length_cm\": 154.5,\n",
      "  \"weight_kg\": 42.7,\n",
      "  \"age_years\": 10\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "# Extract only required fields: subject code, gender, length, weight, age\n",
    "required_fields = {\n",
    "    'Subject code number': 'subject_code',\n",
    "    'Gender [M=male F=female]': 'gender',\n",
    "    'Length [cm]': 'length_cm',\n",
    "    'Weight [kg]': 'weight_kg',\n",
    "    'Age [yr]': 'age_years'\n",
    "}\n",
    "\n",
    "# Select and rename columns\n",
    "subjects_info = population_data[list(required_fields.keys())].copy()\n",
    "subjects_info.rename(columns=required_fields, inplace=True)\n",
    "\n",
    "# Convert to list of dictionaries\n",
    "subjects_list = subjects_info.to_dict('records')\n",
    "\n",
    "# Save as JSON\n",
    "json_output_file = ADOLESCENT_OUTPUT_DIR / 'subjects_info.json'\n",
    "with open(json_output_file, 'w') as f:\n",
    "    json.dump(subjects_list, f, indent=2)\n",
    "\n",
    "print(f\"✓ Subject information saved to {json_output_file}\")\n",
    "print(f\"  Total subjects: {len(subjects_list)}\")\n",
    "print(f\"\\nSample entry:\")\n",
    "print(json.dumps(subjects_list[0], indent=2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08890078",
   "metadata": {},
   "source": [
    "## Part 2: Clean MIMIC-III Data\n",
    "\n",
    "### 2.1 Process All MIMIC-III Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0920e0a6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Cleaning function defined\n"
     ]
    }
   ],
   "source": [
    "def clean_mimic_file(file_path, output_dir, nan_threshold=0.8):\n",
    "    \"\"\"\n",
    "    Clean a MIMIC-III file by:\n",
    "    1. Removing rows where all values are NaN\n",
    "    2. Removing columns where >80% of values are NaN\n",
    "    \n",
    "    Args:\n",
    "        file_path: Path to input CSV file\n",
    "        output_dir: Directory to save cleaned file\n",
    "        nan_threshold: Threshold for removing columns (default: 0.8 = 80%)\n",
    "    \n",
    "    Returns:\n",
    "        Dictionary with cleaning statistics\n",
    "    \"\"\"\n",
    "    # Load data\n",
    "    df = pd.read_csv(file_path)\n",
    "    original_rows = len(df)\n",
    "    original_cols = len(df.columns)\n",
    "    \n",
    "    # Step 1: Remove rows where ALL values are NaN (excluding the first column)\n",
    "    # Get all columns except the first one\n",
    "    cols_to_check = df.columns[1:11]\n",
    "    \n",
    "    # Drop rows where all values in these columns are NaN\n",
    "    df_cleaned = df.dropna(subset=cols_to_check, how='all')\n",
    "    rows_after_cleaning = len(df_cleaned)\n",
    "    removed_rows = original_rows - rows_after_cleaning\n",
    "    \n",
    "    # Step 2: Remove columns with >80% NaN values\n",
    "    # Calculate NaN percentage for each column\n",
    "    nan_percentage = df_cleaned.isna().sum() / len(df_cleaned)\n",
    "    \n",
    "    # Keep only columns with NaN percentage <= threshold\n",
    "    cols_to_keep = nan_percentage[nan_percentage <= nan_threshold].index.tolist()\n",
    "    df_cleaned = df_cleaned[cols_to_keep]\n",
    "    \n",
    "    cols_after_cleaning = len(df_cleaned.columns)\n",
    "    removed_cols = original_cols - cols_after_cleaning\n",
    "    \n",
    "    # Save cleaned data\n",
    "    output_file = output_dir / file_path.name\n",
    "    df_cleaned.to_csv(output_file, index=False)\n",
    "    \n",
    "    return {\n",
    "        'filename': file_path.name,\n",
    "        'original_rows': original_rows,\n",
    "        'cleaned_rows': rows_after_cleaning,\n",
    "        'removed_rows': removed_rows,\n",
    "        'original_cols': original_cols,\n",
    "        'cleaned_cols': cols_after_cleaning,\n",
    "        'removed_cols': removed_cols,\n",
    "        'remaining_columns': list(df_cleaned.columns)\n",
    "    }\n",
    "\n",
    "print(\"✓ Cleaning function defined\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "57b84f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 17 MIMIC-III files to process\n",
      "\n",
      "Processing adult_3016412n.csv...\n",
      "  Original: 588,406 rows × 19 cols\n",
      "  Cleaned:  579,065 rows × 18 cols\n",
      "  Removed:  9,341 rows, 1 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, ABP Sys, ABP Dias, ... (+13 more)\n",
      "\n",
      "Processing adult_3190202n.csv...\n",
      "  Original: 2,645 rows × 48 cols\n",
      "  Cleaned:  2,611 rows × 44 cols\n",
      "  Removed:  34 rows, 4 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, ST-III, ... (+39 more)\n",
      "\n",
      "Processing adult_3297027n.csv...\n",
      "  Original: 49,940 rows × 14 cols\n",
      "  Cleaned:  45,958 rows × 13 cols\n",
      "  Removed:  3,982 rows, 1 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, CVP, NBP Sys, ... (+8 more)\n",
      "\n",
      "Processing adult_3362386n.csv...\n",
      "  Original: 2,639 rows × 47 cols\n",
      "  Cleaned:  2,563 rows × 44 cols\n",
      "  Removed:  76 rows, 3 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, ST-III, ... (+39 more)\n",
      "\n",
      "Processing adult_3570073n.csv...\n",
      "  Original: 2,970 rows × 53 cols\n",
      "  Cleaned:  2,967 rows × 10 cols\n",
      "  Removed:  3 rows, 43 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, ABP SYS, ABP DIAS, ... (+5 more)\n",
      "\n",
      "Processing adult_3618048n.csv...\n",
      "  Original: 1,520 rows × 51 cols\n",
      "  Cleaned:  1,520 rows × 44 cols\n",
      "  Removed:  0 rows, 7 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, ST-II, ... (+39 more)\n",
      "\n",
      "Processing adult_3722620n.csv...\n",
      "  Original: 4,309 rows × 68 cols\n",
      "  Cleaned:  4,308 rows × 47 cols\n",
      "  Removed:  1 rows, 21 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, ABP SYS, ABP DIAS, ... (+42 more)\n",
      "\n",
      "Processing adult_3864557n.csv...\n",
      "  Original: 413,611 rows × 18 cols\n",
      "  Cleaned:  410,013 rows × 16 cols\n",
      "  Removed:  3,598 rows, 2 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, ABP Sys, ABP Dias, ... (+11 more)\n",
      "\n",
      "Processing adult_3924317n.csv...\n",
      "  Original: 1,397 rows × 59 cols\n",
      "  Cleaned:  1,388 rows × 44 cols\n",
      "  Removed:  9 rows, 15 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, ST-II, ... (+39 more)\n",
      "\n",
      "Processing neonate_3182898n.csv...\n",
      "  Original: 96,339 rows × 10 cols\n",
      "  Cleaned:  92,720 rows × 8 cols\n",
      "  Removed:  3,619 rows, 2 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, NBP Sys, NBP Dias, ... (+3 more)\n",
      "\n",
      "Processing neonate_3220897n.csv...\n",
      "  Original: 42,218 rows × 5 cols\n",
      "  Cleaned:  38,238 rows × 5 cols\n",
      "  Removed:  3,980 rows, 0 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, SpO2\n",
      "\n",
      "Processing neonate_3306334n.csv...\n",
      "  Original: 181,368 rows × 9 cols\n",
      "  Cleaned:  180,932 rows × 8 cols\n",
      "  Removed:  436 rows, 1 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, NBP Sys, NBP Dias, ... (+3 more)\n",
      "\n",
      "Processing neonate_3479334n.csv...\n",
      "  Original: 662 rows × 4 cols\n",
      "  Cleaned:  574 rows × 4 cols\n",
      "  Removed:  88 rows, 0 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, NBP Sys, NBP Dias, NBP Mean\n",
      "\n",
      "Processing neonate_3632888n.csv...\n",
      "  Original: 96,422 rows × 9 cols\n",
      "  Cleaned:  96,164 rows × 8 cols\n",
      "  Removed:  258 rows, 1 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, NBP Sys, NBP Dias, ... (+3 more)\n",
      "\n",
      "Processing neonate_3716249n.csv...\n",
      "  Original: 9,711 rows × 8 cols\n",
      "  Cleaned:  9,645 rows × 8 cols\n",
      "  Removed:  66 rows, 0 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, NBP Sys, NBP Dias, ... (+3 more)\n",
      "\n",
      "Processing neonate_3875566n.csv...\n",
      "  Original: 183 rows × 5 cols\n",
      "  Cleaned:  127 rows × 5 cols\n",
      "  Removed:  56 rows, 0 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, SpO2\n",
      "\n",
      "Processing neonate_3998381n.csv...\n",
      "  Original: 118,698 rows × 8 cols\n",
      "  Cleaned:  106,008 rows × 5 cols\n",
      "  Removed:  12,690 rows, 3 cols\n",
      "  Remaining columns: Elapsed_Time_Sec, HR, PULSE, RESP, SpO2\n",
      "\n",
      "✓ All files cleaned and saved to ..\\data\\processed\\hr_mimic_iii\n"
     ]
    }
   ],
   "source": [
    "# Get all MIMIC-III CSV files\n",
    "mimic_files = sorted(MIMIC_DIR.glob('*.csv'))\n",
    "print(f\"Found {len(mimic_files)} MIMIC-III files to process\\n\")\n",
    "\n",
    "# Process each file\n",
    "cleaning_stats = []\n",
    "\n",
    "for file_path in mimic_files:\n",
    "    print(f\"Processing {file_path.name}...\")\n",
    "    stats = clean_mimic_file(file_path, MIMIC_OUTPUT_DIR, nan_threshold=0.9)\n",
    "    cleaning_stats.append(stats)\n",
    "    \n",
    "    print(f\"  Original: {stats['original_rows']:,} rows × {stats['original_cols']} cols\")\n",
    "    print(f\"  Cleaned:  {stats['cleaned_rows']:,} rows × {stats['cleaned_cols']} cols\")\n",
    "    print(f\"  Removed:  {stats['removed_rows']:,} rows, {stats['removed_cols']} cols\")\n",
    "    print(f\"  Remaining columns: {', '.join(stats['remaining_columns'][:5])}\" + \n",
    "          (f\", ... (+{len(stats['remaining_columns'])-5} more)\" if len(stats['remaining_columns']) > 5 else \"\"))\n",
    "    print()\n",
    "\n",
    "print(f\"✓ All files cleaned and saved to {MIMIC_OUTPUT_DIR}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "399ec4e3",
   "metadata": {},
   "source": [
    "### 2.2 Summary Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "64fb5799",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "======================================================================\n",
      "MIMIC-III CLEANING SUMMARY\n",
      "======================================================================\n",
      "Total files processed: 17\n",
      "\n",
      "Rows:\n",
      "  Original total:  1,613,038\n",
      "  Cleaned total:   1,574,801\n",
      "  Removed total:   38,237 (2.4%)\n",
      "\n",
      "Columns (average):\n",
      "  Original:  25.6\n",
      "  Cleaned:   19.5\n",
      "  Removed:   6.1\n",
      "======================================================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>cleaned_rows</th>\n",
       "      <th>cleaned_cols</th>\n",
       "      <th>removed_rows</th>\n",
       "      <th>removed_cols</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>adult_3016412n.csv</td>\n",
       "      <td>579065</td>\n",
       "      <td>18</td>\n",
       "      <td>9341</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>adult_3190202n.csv</td>\n",
       "      <td>2611</td>\n",
       "      <td>44</td>\n",
       "      <td>34</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>adult_3297027n.csv</td>\n",
       "      <td>45958</td>\n",
       "      <td>13</td>\n",
       "      <td>3982</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>adult_3362386n.csv</td>\n",
       "      <td>2563</td>\n",
       "      <td>44</td>\n",
       "      <td>76</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>adult_3570073n.csv</td>\n",
       "      <td>2967</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>adult_3618048n.csv</td>\n",
       "      <td>1520</td>\n",
       "      <td>44</td>\n",
       "      <td>0</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>adult_3722620n.csv</td>\n",
       "      <td>4308</td>\n",
       "      <td>47</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>adult_3864557n.csv</td>\n",
       "      <td>410013</td>\n",
       "      <td>16</td>\n",
       "      <td>3598</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>adult_3924317n.csv</td>\n",
       "      <td>1388</td>\n",
       "      <td>44</td>\n",
       "      <td>9</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>neonate_3182898n.csv</td>\n",
       "      <td>92720</td>\n",
       "      <td>8</td>\n",
       "      <td>3619</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>neonate_3220897n.csv</td>\n",
       "      <td>38238</td>\n",
       "      <td>5</td>\n",
       "      <td>3980</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>neonate_3306334n.csv</td>\n",
       "      <td>180932</td>\n",
       "      <td>8</td>\n",
       "      <td>436</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>neonate_3479334n.csv</td>\n",
       "      <td>574</td>\n",
       "      <td>4</td>\n",
       "      <td>88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>neonate_3632888n.csv</td>\n",
       "      <td>96164</td>\n",
       "      <td>8</td>\n",
       "      <td>258</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>neonate_3716249n.csv</td>\n",
       "      <td>9645</td>\n",
       "      <td>8</td>\n",
       "      <td>66</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>neonate_3875566n.csv</td>\n",
       "      <td>127</td>\n",
       "      <td>5</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>neonate_3998381n.csv</td>\n",
       "      <td>106008</td>\n",
       "      <td>5</td>\n",
       "      <td>12690</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                filename  cleaned_rows  cleaned_cols  removed_rows  \\\n",
       "0     adult_3016412n.csv        579065            18          9341   \n",
       "1     adult_3190202n.csv          2611            44            34   \n",
       "2     adult_3297027n.csv         45958            13          3982   \n",
       "3     adult_3362386n.csv          2563            44            76   \n",
       "4     adult_3570073n.csv          2967            10             3   \n",
       "5     adult_3618048n.csv          1520            44             0   \n",
       "6     adult_3722620n.csv          4308            47             1   \n",
       "7     adult_3864557n.csv        410013            16          3598   \n",
       "8     adult_3924317n.csv          1388            44             9   \n",
       "9   neonate_3182898n.csv         92720             8          3619   \n",
       "10  neonate_3220897n.csv         38238             5          3980   \n",
       "11  neonate_3306334n.csv        180932             8           436   \n",
       "12  neonate_3479334n.csv           574             4            88   \n",
       "13  neonate_3632888n.csv         96164             8           258   \n",
       "14  neonate_3716249n.csv          9645             8            66   \n",
       "15  neonate_3875566n.csv           127             5            56   \n",
       "16  neonate_3998381n.csv        106008             5         12690   \n",
       "\n",
       "    removed_cols  \n",
       "0              1  \n",
       "1              4  \n",
       "2              1  \n",
       "3              3  \n",
       "4             43  \n",
       "5              7  \n",
       "6             21  \n",
       "7              2  \n",
       "8             15  \n",
       "9              2  \n",
       "10             0  \n",
       "11             1  \n",
       "12             0  \n",
       "13             1  \n",
       "14             0  \n",
       "15             0  \n",
       "16             3  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create summary dataframe\n",
    "summary_df = pd.DataFrame(cleaning_stats)\n",
    "\n",
    "# Calculate totals and averages\n",
    "total_original_rows = summary_df['original_rows'].sum()\n",
    "total_cleaned_rows = summary_df['cleaned_rows'].sum()\n",
    "total_removed_rows = summary_df['removed_rows'].sum()\n",
    "\n",
    "avg_original_cols = summary_df['original_cols'].mean()\n",
    "avg_cleaned_cols = summary_df['cleaned_cols'].mean()\n",
    "\n",
    "print(\"=\" * 70)\n",
    "print(\"MIMIC-III CLEANING SUMMARY\")\n",
    "print(\"=\" * 70)\n",
    "print(f\"Total files processed: {len(mimic_files)}\")\n",
    "print(f\"\\nRows:\")\n",
    "print(f\"  Original total:  {total_original_rows:,}\")\n",
    "print(f\"  Cleaned total:   {total_cleaned_rows:,}\")\n",
    "print(f\"  Removed total:   {total_removed_rows:,} ({total_removed_rows/total_original_rows*100:.1f}%)\")\n",
    "print(f\"\\nColumns (average):\")\n",
    "print(f\"  Original:  {avg_original_cols:.1f}\")\n",
    "print(f\"  Cleaned:   {avg_cleaned_cols:.1f}\")\n",
    "print(f\"  Removed:   {avg_original_cols - avg_cleaned_cols:.1f}\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display detailed summary\n",
    "summary_df[['filename', 'cleaned_rows', 'cleaned_cols', 'removed_rows', 'removed_cols']]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70a76c2b",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "### Output Files\n",
    "\n",
    "#### Adolescent Data (hr_adolescent):\n",
    "- **Heart Rate CSV Files**: Individual CSV files for each subject in `data/processed/hr_adolescent/`\n",
    "  - Format: `subject_<code>_hr.csv`\n",
    "- **Heart Rate TXT Files**: Text format for prompts in `data/processed/hr_adolescent/`\n",
    "  - Format: `subject_<code>_hr.txt`\n",
    "  - Example: `Time: 00:00 - heart rate [#/min]: 64`\n",
    "- **Metadata**: `subjects_info.json` containing subject information (code, gender, length, weight, age)\n",
    "\n",
    "#### MIMIC-III Data (hr_mimic_iii):\n",
    "- **Cleaned CSV Files**: All MIMIC-III files cleaned and saved in `data/processed/hr_mimic_iii/`\n",
    "  - Removed rows with all NaN values (excluding first column)\n",
    "  - Removed columns with >80% NaN values\n",
    "- **Text Files**: Prompt-ready text format in `data/processed/hr_mimic_iii/`\n",
    "  - Example: `Time: 31s - HR: 117, Rhythm Status: 63005`\n",
    "  - Only non-null values are included in each line\n",
    "\n",
    "### Text Format Details\n",
    "Each text file contains one line per row with the format:\n",
    "```\n",
    "Time: <time_value> - Feature1: value1, Feature2: value2, ...\n",
    "```\n",
    "- Only features with non-null values are included\n",
    "- Perfect for creating prompts for LLM-based analysis\n",
    "- Time format varies by dataset (timestamp for adolescent, elapsed seconds for MIMIC-III)\n",
    "\n",
    "All processed data is ready for further analysis!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a8f0aa7",
   "metadata": {},
   "source": [
    "## Part 3: Create Text Versions for Prompts\n",
    "\n",
    "### 3.1 Convert CSV Files to Text Format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "6ff5a309",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✓ Text conversion function defined\n"
     ]
    }
   ],
   "source": [
    "def csv_to_text_format(csv_path, output_path, time_column=None):\n",
    "    \"\"\"\n",
    "    Convert a CSV file to a text format suitable for prompts.\n",
    "    Each row becomes a line with format: Time: XX - Feature1: value1, Feature2: value2, ...\n",
    "    Only non-null values are included.\n",
    "    \n",
    "    Args:\n",
    "        csv_path: Path to input CSV file\n",
    "        output_path: Path to output text file\n",
    "        time_column: Name of the time column (if None, uses row index)\n",
    "    \n",
    "    Returns:\n",
    "        Number of lines written\n",
    "    \"\"\"\n",
    "    # Read CSV\n",
    "    df = pd.read_csv(csv_path)\n",
    "    \n",
    "    lines = []\n",
    "    \n",
    "    for idx, row in df.iterrows():\n",
    "        # Start building the line\n",
    "        if time_column and time_column in df.columns and pd.notna(row[time_column]):\n",
    "            # Use the actual time column value\n",
    "            time_value = row[time_column]\n",
    "            line_parts = [f\"Time: {time_value}\"]\n",
    "        else:\n",
    "            # Use row index or elapsed time\n",
    "            if 'Elapsed_Time_Sec' in df.columns and pd.notna(row['Elapsed_Time_Sec']):\n",
    "                line_parts = [f\"Time: {int(row['Elapsed_Time_Sec'])}s\"]\n",
    "            else:\n",
    "                line_parts = [f\"Time: {idx}\"]\n",
    "        \n",
    "        # Add all non-null features (excluding the time column)\n",
    "        for col in df.columns:\n",
    "            # Skip time columns and any column we already used\n",
    "            if col in ['Elapsed_Time_Sec', time_column, 'Subject code number', \n",
    "                       'Local datetime [ISO8601]', 'Local date [yyyy-mm-dd]', \n",
    "                       'Local time [hh:mm]', 'UTC offset [hr]']:\n",
    "                continue\n",
    "            \n",
    "            # Only add if value is not null\n",
    "            if pd.notna(row[col]):\n",
    "                value = row[col]\n",
    "                # Format the value appropriately\n",
    "                if isinstance(value, float):\n",
    "                    # Round to reasonable precision\n",
    "                    if value.is_integer():\n",
    "                        line_parts.append(f\"{col}: {int(value)}\")\n",
    "                    else:\n",
    "                        line_parts.append(f\"{col}: {value:.2f}\")\n",
    "                else:\n",
    "                    line_parts.append(f\"{col}: {value}\")\n",
    "        \n",
    "        # Join all parts with \" - \" for first separator, then \", \" for features\n",
    "        if len(line_parts) > 1:\n",
    "            line = line_parts[0] + \" - \" + \", \".join(line_parts[1:])\n",
    "            lines.append(line)\n",
    "    \n",
    "    # Write to file\n",
    "    with open(output_path, 'w') as f:\n",
    "        f.write('\\n'.join(lines))\n",
    "    \n",
    "    return len(lines)\n",
    "\n",
    "print(\"✓ Text conversion function defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0088925d",
   "metadata": {},
   "source": [
    "### 3.2 Process Adolescent Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "446099fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 24 adolescent files to text format...\n",
      "\n",
      "  ✓ subject_903_hr.csv → subject_903_hr.txt (118,354 lines)\n",
      "  ✓ subject_907_hr.csv → subject_907_hr.txt (108,150 lines)\n",
      "  ✓ subject_911_hr.csv → subject_911_hr.txt (122,065 lines)\n",
      "  ✓ subject_912_hr.csv → subject_912_hr.txt (118,311 lines)\n",
      "  ✓ subject_914_hr.csv → subject_914_hr.txt (109,735 lines)\n",
      "  ✓ subject_918_hr.csv → subject_918_hr.txt (119,580 lines)\n",
      "  ✓ subject_919_hr.csv → subject_919_hr.txt (111,615 lines)\n",
      "  ✓ subject_926_hr.csv → subject_926_hr.txt (123,220 lines)\n",
      "  ✓ subject_929_hr.csv → subject_929_hr.txt (121,288 lines)\n",
      "  ✓ subject_936_hr.csv → subject_936_hr.txt (113,827 lines)\n",
      "  ✓ subject_941_hr.csv → subject_941_hr.txt (122,008 lines)\n",
      "  ✓ subject_943_hr.csv → subject_943_hr.txt (116,360 lines)\n",
      "  ✓ subject_944_hr.csv → subject_944_hr.txt (113,665 lines)\n",
      "  ✓ subject_959_hr.csv → subject_959_hr.txt (116,882 lines)\n",
      "  ✓ subject_962_hr.csv → subject_962_hr.txt (123,846 lines)\n",
      "  ✓ subject_964_hr.csv → subject_964_hr.txt (102,367 lines)\n",
      "  ✓ subject_967_hr.csv → subject_967_hr.txt (114,783 lines)\n",
      "  ✓ subject_973_hr.csv → subject_973_hr.txt (124,691 lines)\n",
      "  ✓ subject_974_hr.csv → subject_974_hr.txt (113,884 lines)\n",
      "  ✓ subject_976_hr.csv → subject_976_hr.txt (109,064 lines)\n",
      "  ✓ subject_981_hr.csv → subject_981_hr.txt (112,110 lines)\n",
      "  ✓ subject_987_hr.csv → subject_987_hr.txt (112,867 lines)\n",
      "  ✓ subject_990_hr.csv → subject_990_hr.txt (111,656 lines)\n",
      "  ✓ subject_995_hr.csv → subject_995_hr.txt (111,479 lines)\n",
      "\n",
      "✓ All adolescent files converted to text format\n"
     ]
    }
   ],
   "source": [
    "# Create text versions of adolescent heart rate files\n",
    "adolescent_csv_files = sorted(ADOLESCENT_OUTPUT_DIR.glob('subject_*_hr.csv'))\n",
    "print(f\"Converting {len(adolescent_csv_files)} adolescent files to text format...\\n\")\n",
    "\n",
    "for csv_file in adolescent_csv_files:\n",
    "    # Create output filename (replace .csv with .txt)\n",
    "    txt_file = csv_file.with_suffix('.txt')\n",
    "    \n",
    "    # Convert using the local time column\n",
    "    num_lines = csv_to_text_format(csv_file, txt_file, time_column='Local time [hh:mm]')\n",
    "    \n",
    "    print(f\"  ✓ {csv_file.name} → {txt_file.name} ({num_lines:,} lines)\")\n",
    "\n",
    "print(f\"\\n✓ All adolescent files converted to text format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8c041971",
   "metadata": {},
   "source": [
    "### 3.3 Process MIMIC-III Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ef968237",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Converting 17 MIMIC-III files to text format...\n",
      "\n",
      "  ✓ adult_3016412n.csv → adult_3016412n.txt (579,065 lines)\n",
      "  ✓ adult_3190202n.csv → adult_3190202n.txt (2,611 lines)\n",
      "  ✓ adult_3297027n.csv → adult_3297027n.txt (45,958 lines)\n",
      "  ✓ adult_3362386n.csv → adult_3362386n.txt (2,563 lines)\n",
      "  ✓ adult_3570073n.csv → adult_3570073n.txt (2,967 lines)\n",
      "  ✓ adult_3618048n.csv → adult_3618048n.txt (1,520 lines)\n",
      "  ✓ adult_3722620n.csv → adult_3722620n.txt (4,308 lines)\n",
      "  ✓ adult_3864557n.csv → adult_3864557n.txt (410,013 lines)\n",
      "  ✓ adult_3924317n.csv → adult_3924317n.txt (1,388 lines)\n",
      "  ✓ neonate_3182898n.csv → neonate_3182898n.txt (92,720 lines)\n",
      "  ✓ neonate_3220897n.csv → neonate_3220897n.txt (38,238 lines)\n",
      "  ✓ neonate_3306334n.csv → neonate_3306334n.txt (180,932 lines)\n",
      "  ✓ neonate_3479334n.csv → neonate_3479334n.txt (574 lines)\n",
      "  ✓ neonate_3632888n.csv → neonate_3632888n.txt (96,164 lines)\n",
      "  ✓ neonate_3716249n.csv → neonate_3716249n.txt (9,645 lines)\n",
      "  ✓ neonate_3875566n.csv → neonate_3875566n.txt (127 lines)\n",
      "  ✓ neonate_3998381n.csv → neonate_3998381n.txt (106,008 lines)\n",
      "\n",
      "✓ All MIMIC-III files converted to text format\n"
     ]
    }
   ],
   "source": [
    "# Create text versions of MIMIC-III files\n",
    "mimic_csv_files = sorted(MIMIC_OUTPUT_DIR.glob('*.csv'))\n",
    "print(f\"Converting {len(mimic_csv_files)} MIMIC-III files to text format...\\n\")\n",
    "\n",
    "for csv_file in mimic_csv_files:\n",
    "    # Create output filename (replace .csv with .txt)\n",
    "    txt_file = csv_file.with_suffix('.txt')\n",
    "    \n",
    "    # Convert (MIMIC uses Elapsed_Time_Sec)\n",
    "    num_lines = csv_to_text_format(csv_file, txt_file)\n",
    "    \n",
    "    print(f\"  ✓ {csv_file.name} → {txt_file.name} ({num_lines:,} lines)\")\n",
    "\n",
    "print(f\"\\n✓ All MIMIC-III files converted to text format\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "333291cb",
   "metadata": {},
   "source": [
    "### 3.4 Sample Text Output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "122ba350",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample from subject_903_hr.txt:\n",
      "======================================================================\n",
      "Time: 00:00 - heart rate [#/min]: 64\n",
      "Time: 00:01 - heart rate [#/min]: 67\n",
      "Time: 00:02 - heart rate [#/min]: 66\n",
      "Time: 00:03 - heart rate [#/min]: 68\n",
      "Time: 00:04 - heart rate [#/min]: 66\n",
      "Time: 00:05 - heart rate [#/min]: 66\n",
      "Time: 00:06 - heart rate [#/min]: 65\n",
      "Time: 00:07 - heart rate [#/min]: 67\n",
      "Time: 00:08 - heart rate [#/min]: 66\n",
      "Time: 00:09 - heart rate [#/min]: 67\n",
      "...\n",
      "======================================================================\n",
      "\n",
      "\n",
      "Sample from adult_3016412n.txt:\n",
      "======================================================================\n",
      "Time: 31s - HR: 117, Rhythm Status: 63005\n",
      "Time: 32s - HR: 117, Rhythm Status: 63005\n",
      "Time: 33s - HR: 118, Rhythm Status: 63005\n",
      "Time: 34s - HR: 115, Rhythm Status: 63005\n",
      "Time: 42s - HR: 110, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "Time: 43s - HR: 112, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "Time: 44s - HR: 116, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "Time: 45s - HR: 113, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "Time: 46s - HR: 110, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "Time: 47s - HR: 113, PVC Rate per Minute: 0, Rhythm Status: 63004\n",
      "...\n",
      "======================================================================\n"
     ]
    }
   ],
   "source": [
    "# Display sample from an adolescent file\n",
    "sample_adolescent = sorted(ADOLESCENT_OUTPUT_DIR.glob('subject_*_hr.txt'))[0]\n",
    "print(f\"Sample from {sample_adolescent.name}:\")\n",
    "print(\"=\" * 70)\n",
    "with open(sample_adolescent, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in lines[:10]:  # Show first 10 lines\n",
    "        print(line.rstrip())\n",
    "print(\"...\")\n",
    "print(\"=\" * 70)\n",
    "\n",
    "# Display sample from a MIMIC file\n",
    "print(f\"\\n\")\n",
    "sample_mimic = sorted(MIMIC_OUTPUT_DIR.glob('*.txt'))[0]\n",
    "print(f\"Sample from {sample_mimic.name}:\")\n",
    "print(\"=\" * 70)\n",
    "with open(sample_mimic, 'r') as f:\n",
    "    lines = f.readlines()\n",
    "    # Find lines with actual data (skip initial empty lines)\n",
    "    data_lines = [l for l in lines if ' - ' in l]\n",
    "    for line in data_lines[:10]:  # Show first 10 data lines\n",
    "        print(line.rstrip())\n",
    "print(\"...\")\n",
    "print(\"=\" * 70)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bf3af5c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
